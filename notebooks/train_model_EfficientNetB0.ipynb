{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1715861915523,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"KBhypBw-PXiO"},"outputs":[],"source":["import numpy as np\n","\n","import tensorflow as tf\n","\n","from keras.models import Model\n","from keras.layers import Dense, Input, GlobalAveragePooling2D\n","\n","from tensorflow.keras.preprocessing import image\n","\n","from keras_efficientnets import EfficientNetB0\n","\n","from PIL import Image\n","import os\n","\n","from keras.callbacks import EarlyStopping\n","\n","from keras.callbacks import LearningRateScheduler\n","import keras.backend as K\n","\n","from sklearn.preprocessing import LabelBinarizer\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["'''\n","Manual preprocessing for image datasets\n","'''\n","\n","image_folder = r\"../img\"\n","images = []\n","labels = []\n","i = 0\n","\n","for folder_imgName in os.listdir(image_folder):\n","\n","    for files_name in os.listdir(image_folder + '/' + folder_imgName):\n","\n","        if files_name.endswith(\".png\"):\n","            folder_path = image_folder + '/' + folder_imgName\n","\n","            # img loading\n","            img = Image.open(os.path.join(folder_path, files_name))\n","            lbl = folder_imgName\n","\n","            # preprocessing image\n","            img = img.resize((224, 224))  # resizingf for model\n","            img = np.array(img) / 255.0  # Normalisation (between 0 & 1)\n","\n","\n","            images.append(img)\n","            labels.append(lbl)\n","\n","            if i == 0:\n","                img_test= img\n","                i==1\n","\n","\n","# preprocessing labels & convert to numpy array\n","labelB = LabelBinarizer()\n","train_labels = labelB.fit_transform(labels)\n","\n","# image list to numpy array\n","train_images = np.array(images)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["'''\n","Manual preprocessing for image datasets\n","'''\n","\n","image_folder = r\"../img_val\"\n","images = []\n","labels = []\n","i = 0\n","\n","for folder_imgName in os.listdir(image_folder):\n","\n","    for files_name in os.listdir(image_folder + '/' + folder_imgName):\n","\n","        if files_name.endswith(\".png\"):\n","            folder_path = image_folder + '/' + folder_imgName\n","\n","            # img loading\n","            img = Image.open(os.path.join(folder_path, files_name))\n","            lbl = folder_imgName\n","\n","            # preprocessing image\n","            img = img.resize((224, 224))  # resizingf for model\n","            img = np.array(img) / 255.0  # Normalisation (between 0 & 1)\n","\n","\n","            images.append(img)\n","            labels.append(lbl)\n","\n","            if i == 0:\n","                imgs_test= img\n","                i==1\n","\n","\n","# preprocessing labels & convert to numpy array\n","labelB = LabelBinarizer()\n","val_labels = labelB.fit_transform(labels)\n","\n","# image list to numpy array\n","val_images = np.array(images)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715861948689,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"YTo5UbLEPXiZ"},"outputs":[],"source":["# définition des paramètres personalisés\n","\n","# personal layers for VGG16 models\n","n_classes = 7\n","n_layers = 7\n","n_neurons_BeforeLast = 128\n","f_activation = 'relu'\n","f_activation_lastLayer = 'softmax'\n","\n","# personal parameters for compilation\n","optimizer = 'Adagrad'\n","loss = 'categorical_crossentropy'\n","\n","# personnal parameters for training (fitness)\n","epochs = 100\n","batch_size = 32\n","\n","#numéro de l'essai\n","num_essai = '0_efficientNet'\n","\n","file_name = (str(num_essai) + '_' + str(n_classes) + '_' + str(n_layers) +\n","'_' + str(n_neurons_BeforeLast) + '_' + str(f_activation) +\n","'_' + str(f_activation_lastLayer) + '_' + str(optimizer) +\n","'_' + str(loss) + '_' + str(epochs) + '_' + str(batch_size) )"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":823,"status":"ok","timestamp":1715861949509,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"qxe7N89TPXiZ"},"outputs":[],"source":["# Model EfficientNetB0 loading without fully connected layers\n","\n","input_shape = (224, 224, 3)  # Spécifiez la taille de l'entrée\n","input_tensor = Input(shape=input_shape)\n","base_model = EfficientNetB0(input_tensor=input_tensor, include_top=False, weights='imagenet')#, classes=1000)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715861949509,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"nHMdt7bbPXia"},"outputs":[],"source":["# Freeze convolution layers to avoid training\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1715861949924,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"TVE_7ntqPXia","outputId":"834353eb-267c-4fc9-d2af-b4d567e8e53a"},"outputs":[],"source":["# Add personnal layers for training\n","x = base_model.output\n","\n","x = GlobalAveragePooling2D()(x)\n","\n","for i in range(n_layers):\n","    x = Dense(n_neurons_BeforeLast * (n_classes-i), activation=f_activation)(x) #personal layer\n","\n","\n","predictions = Dense(n_classes, activation=f_activation_lastLayer)(x)  "]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715861949924,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"hwMLwYxJPXib"},"outputs":[],"source":["# generate model VGG16 with personal fully connected layers\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715861949924,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"JqthTJWZPXib"},"outputs":[],"source":["model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# def scheduler(epoch, lr):\n","#     if epoch < 12:\n","#         return lr\n","#     else:\n","#         return lr * K.exp(-0.1)\n","\n","# lr_scheduler = LearningRateScheduler(scheduler)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Define early stopping callback\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":725},"executionInfo":{"elapsed":7124,"status":"error","timestamp":1715861957044,"user":{"displayName":"Dimitri Lefebvre","userId":"04457642718130606157"},"user_tz":-120},"id":"ugEgcIJjPXib","outputId":"6ba2e205-b1f9-45fc-9422-79bfcfb11665"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","175/175 [==============================] - 14s 57ms/step - loss: 1.8897 - accuracy: 0.3202 - val_loss: 1.8116 - val_accuracy: 0.4616\n","Epoch 2/100\n","175/175 [==============================] - 9s 51ms/step - loss: 1.6498 - accuracy: 0.5013 - val_loss: 1.4453 - val_accuracy: 0.5920\n","Epoch 3/100\n","175/175 [==============================] - 9s 51ms/step - loss: 1.2221 - accuracy: 0.6520 - val_loss: 1.0339 - val_accuracy: 0.6938\n","Epoch 4/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.8944 - accuracy: 0.7311 - val_loss: 0.7809 - val_accuracy: 0.7518\n","Epoch 5/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.7018 - accuracy: 0.7730 - val_loss: 0.6231 - val_accuracy: 0.8062\n","Epoch 6/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.5863 - accuracy: 0.8079 - val_loss: 0.5225 - val_accuracy: 0.8348\n","Epoch 7/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.5109 - accuracy: 0.8288 - val_loss: 0.4579 - val_accuracy: 0.8473\n","Epoch 8/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.4537 - accuracy: 0.8471 - val_loss: 0.4061 - val_accuracy: 0.8723\n","Epoch 9/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.4076 - accuracy: 0.8618 - val_loss: 0.3682 - val_accuracy: 0.8786\n","Epoch 10/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.3753 - accuracy: 0.8737 - val_loss: 0.3403 - val_accuracy: 0.8920\n","Epoch 11/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.3409 - accuracy: 0.8854 - val_loss: 0.3260 - val_accuracy: 0.9054\n","Epoch 12/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.3184 - accuracy: 0.8932 - val_loss: 0.3066 - val_accuracy: 0.9018\n","Epoch 13/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2958 - accuracy: 0.9002 - val_loss: 0.2855 - val_accuracy: 0.9071\n","Epoch 14/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2785 - accuracy: 0.9082 - val_loss: 0.2724 - val_accuracy: 0.9134\n","Epoch 15/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2607 - accuracy: 0.9159 - val_loss: 0.2352 - val_accuracy: 0.9232\n","Epoch 16/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2484 - accuracy: 0.9168 - val_loss: 0.2457 - val_accuracy: 0.9170\n","Epoch 17/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.2332 - accuracy: 0.9229 - val_loss: 0.2120 - val_accuracy: 0.9375\n","Epoch 18/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2245 - accuracy: 0.9237 - val_loss: 0.2148 - val_accuracy: 0.9321\n","Epoch 19/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2105 - accuracy: 0.9334 - val_loss: 0.1923 - val_accuracy: 0.9402\n","Epoch 20/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.2056 - accuracy: 0.9321 - val_loss: 0.1842 - val_accuracy: 0.9438\n","Epoch 21/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1955 - accuracy: 0.9337 - val_loss: 0.1925 - val_accuracy: 0.9304\n","Epoch 22/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1873 - accuracy: 0.9384 - val_loss: 0.1772 - val_accuracy: 0.9438\n","Epoch 23/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.1779 - accuracy: 0.9411 - val_loss: 0.1644 - val_accuracy: 0.9527\n","Epoch 24/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.1728 - accuracy: 0.9423 - val_loss: 0.1665 - val_accuracy: 0.9500\n","Epoch 25/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.1669 - accuracy: 0.9450 - val_loss: 0.1456 - val_accuracy: 0.9589\n","Epoch 26/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.1583 - accuracy: 0.9489 - val_loss: 0.1591 - val_accuracy: 0.9491\n","Epoch 27/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1522 - accuracy: 0.9520 - val_loss: 0.1611 - val_accuracy: 0.9580\n","Epoch 28/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1465 - accuracy: 0.9541 - val_loss: 0.1390 - val_accuracy: 0.9554\n","Epoch 29/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.1410 - accuracy: 0.9548 - val_loss: 0.1299 - val_accuracy: 0.9652\n","Epoch 30/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.1374 - accuracy: 0.9563 - val_loss: 0.1222 - val_accuracy: 0.9696\n","Epoch 31/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1318 - accuracy: 0.9589 - val_loss: 0.1198 - val_accuracy: 0.9679\n","Epoch 32/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1313 - accuracy: 0.9589 - val_loss: 0.1185 - val_accuracy: 0.9670\n","Epoch 33/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1251 - accuracy: 0.9645 - val_loss: 0.1101 - val_accuracy: 0.9705\n","Epoch 34/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1191 - accuracy: 0.9639 - val_loss: 0.1109 - val_accuracy: 0.9705\n","Epoch 35/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1177 - accuracy: 0.9636 - val_loss: 0.1073 - val_accuracy: 0.9696\n","Epoch 36/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1152 - accuracy: 0.9659 - val_loss: 0.1056 - val_accuracy: 0.9670\n","Epoch 37/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1111 - accuracy: 0.9648 - val_loss: 0.1053 - val_accuracy: 0.9714\n","Epoch 38/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1059 - accuracy: 0.9677 - val_loss: 0.1011 - val_accuracy: 0.9714\n","Epoch 39/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1037 - accuracy: 0.9696 - val_loss: 0.1035 - val_accuracy: 0.9688\n","Epoch 40/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.1002 - accuracy: 0.9709 - val_loss: 0.0877 - val_accuracy: 0.9750\n","Epoch 41/100\n","175/175 [==============================] - 9s 51ms/step - loss: 0.0984 - accuracy: 0.9714 - val_loss: 0.0816 - val_accuracy: 0.9821\n","Epoch 42/100\n","175/175 [==============================] - 9s 52ms/step - loss: 0.0927 - accuracy: 0.9732 - val_loss: 0.0852 - val_accuracy: 0.9777\n","Epoch 43/100\n","175/175 [==============================] - 9s 53ms/step - loss: 0.0909 - accuracy: 0.9734 - val_loss: 0.0838 - val_accuracy: 0.9768\n","Epoch 44/100\n","175/175 [==============================] - 9s 53ms/step - loss: 0.0891 - accuracy: 0.9754 - val_loss: 0.0806 - val_accuracy: 0.9795\n","Epoch 45/100\n","175/175 [==============================] - 9s 53ms/step - loss: 0.0857 - accuracy: 0.9770 - val_loss: 0.1026 - val_accuracy: 0.9679\n","Epoch 46/100\n","175/175 [==============================] - 9s 53ms/step - loss: 0.0824 - accuracy: 0.9777 - val_loss: 0.0758 - val_accuracy: 0.9795\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x218d14ff0a0>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Model training\n","model.fit(train_images, train_labels, epochs= epochs, batch_size= batch_size, validation_data=(val_images, val_labels), callbacks=[early_stopping])#, lr_scheduler"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../model_saved/0_efficientNet_model.h5py\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../model_saved/0_efficientNet_model.h5py\\assets\n","c:\\Users\\dimle\\Documents\\lego_classification\\.conda\\lib\\site-packages\\keras\\engine\\functional.py:1384: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n","c:\\Users\\dimle\\Documents\\lego_classification\\.conda\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  return generic_utils.serialize_keras_object(obj)\n"]}],"source":["model.save(f\"../model_saved/{num_essai}_model.h5py\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
